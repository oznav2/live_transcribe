# Live Transcription Service - Project Summary

**Version:** 2.0  
**Last Updated:** 2025-11-02  
**Total Lines of Code:** 3,618 (app.py)  
**Status:** Production Ready

---

## ğŸ¯ Overview

A high-performance, real-time audio transcription service built with FastAPI and Whisper models. Supports live streaming, VOD transcription, speaker diarization, and YouTube video metadata extraction. Optimized for Hebrew (Ivrit) and multilingual content with bilingual UI support.

---

## ğŸ—ï¸ Architecture

### Technology Stack

**Backend:**
- **Framework:** FastAPI 0.109.0 with WebSocket support
- **Transcription:** 
  - faster-whisper (primary, CT2 models)
  - openai-whisper (fallback)
  - Deepgram SDK 5.2.0 (cloud option)
- **Audio Processing:** FFmpeg, PyAudio, yt-dlp 2024.10.7
- **Speaker Diarization:** pyannote.audio 3.x (optional)
- **Async:** asyncio with ThreadPoolExecutor
- **Python Version:** 3.11

**Frontend:**
- **UI Framework:** Vanilla JavaScript with Tailwind CSS
- **WebSocket:** Real-time bidirectional communication
- **RTL Support:** Hebrew (right-to-left) and English (left-to-right)
- **Responsive:** Mobile-friendly design

**Infrastructure:**
- **Containerization:** Docker with multi-stage builds
- **GPU Support:** CUDA 11.8/12.1 for accelerated transcription
- **Caching:** Multi-level caching (audio, downloads, models)
- **Health Checks:** Built-in health and diagnostics endpoints

---

## ğŸ¨ Key Features

### 1. **Multi-Source Audio Input**
- âœ… Live audio streams (HLS, m3u8)
- âœ… YouTube videos (all formats)
- âœ… Direct video/audio URLs
- âœ… Vimeo, Dailymotion, Twitter, etc.
- âœ… First 60-second capture mode

### 2. **Transcription Models**
- **Ivrit CT2:** `ivrit-ai/whisper-large-v3-turbo-ct2` (Hebrew-optimized)
- **Whisper V3 Turbo:** `large-v3-turbo` (multilingual)
- **Deepgram Nova-2:** Cloud-based (best for English)
- **Model Selection:** Runtime model switching

### 3. **Speaker Diarization**
- âœ… Automatic speaker detection
- âœ… Speaker labeling (SPEAKER_1, SPEAKER_2, etc.)
- âœ… Hebrew labels (×“×•×‘×¨_1, ×“×•×‘×¨_2) for Ivrit models
- âœ… Timestamp-aligned speaker attribution
- âœ… Pyannote.audio integration

### 4. **YouTube Video Metadata**
- âœ… Auto-detection of YouTube URLs
- âœ… Video title, channel, duration, views
- âœ… Thumbnail display
- âœ… Bilingual UI (Hebrew RTL / English LTR)
- âœ… Dynamic language switching
- âœ… Debounced API calls (500ms)

### 5. **Real-Time Progress Tracking**
- âœ… Download progress with ETA
- âœ… Transcription progress by chunk
- âœ… 100% completion guarantee
- âœ… Speed metrics (MB/s, chunks/s)
- âœ… Non-blocking async updates

### 6. **Caching System**
- **Audio Cache:** SHA256-based deduplication
- **Download Cache:** URL-based with 1-hour TTL
- **Model Cache:** In-memory loaded models
- **HTML Cache:** Static assets cached at startup

### 7. **Bilingual Interface**
- **Hebrew Mode:** RTL layout, Hebrew labels
- **English Mode:** LTR layout, English labels
- **Auto-detection:** Based on model/language selection
- **Dynamic Switching:** Instant language changes

---

## ğŸ“‚ Project Structure

```
/home/user/webapp/
â”œâ”€â”€ app.py                          # Main application (3,618 lines)
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html                  # Web UI with bilingual support
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ requirements.ivrit.txt          # Ivrit-specific dependencies
â”œâ”€â”€ Dockerfile                      # Standard Docker build
â”œâ”€â”€ Dockerfile.ivrit                # Ivrit-optimized Docker build
â”œâ”€â”€ .env                            # Environment variables (not in repo)
â”œâ”€â”€ cache/                          # Runtime cache directories
â”‚   â”œâ”€â”€ audio/                      # Audio deduplication cache
â”‚   â”œâ”€â”€ downloads/                  # URL download cache
â”‚   â””â”€â”€ captures/                   # First-60s captures
â”œâ”€â”€ logs/                           # Application logs
â””â”€â”€ docs/                           # Documentation
    â”œâ”€â”€ PROJECT_SUMMARY.md          # This file
    â”œâ”€â”€ API.md                      # API documentation
    â”œâ”€â”€ APP_PY_ANALYSIS.md          # Function-level analysis
    â”œâ”€â”€ FEATURE_VIDEO_METADATA.md   # Video metadata feature docs
    â”œâ”€â”€ FIXES_*.md                  # Bug fix documentation
    â””â”€â”€ plans/                      # Implementation plans
```

---

## ğŸ”§ Core Components

### 1. **Application Lifecycle**
- **Startup:** `lifespan()` async context manager
  - Load default model
  - Initialize cache directories
  - Cache index.html
  - Setup logging
- **Runtime:** FastAPI with uvicorn ASGI server
- **Shutdown:** Graceful cleanup

### 2. **Model Management**
- **Thread-Safe Loading:** Double-check locking pattern
- **Global Cache:** Single model instance per type
- **Dynamic Switching:** Load models on-demand
- **GPU/CPU Fallback:** Automatic device selection

### 3. **Audio Pipeline**
```
Input URL/Stream
    â†“
should_use_ytdlp() â†’ Route decision
    â†“
download_with_fallback() â†’ yt-dlp â†’ ffmpeg
    â†“
Cached? â†’ get_cached_download()
    â†“
split_audio_for_incremental() â†’ Chunks
    â†“
transcribe_with_incremental_output() â†’ Executor
    â†“
WebSocket Updates â†’ UI
    â†“
Diarization? â†’ transcribe_with_diarization()
    â†“
Final Results
```

### 4. **WebSocket Protocol**
- **Connection:** `/ws/transcribe`
- **Messages:**
  - `status`: Status updates
  - `download_progress`: Download metrics
  - `transcription_progress`: Transcription metrics
  - `transcription_chunk`: Incremental text
  - `cached_file`: Cache hit notification
  - `complete`: Job completion
  - `error`: Error messages

### 5. **Async Architecture**
- **Event Loop:** Non-blocking operations
- **Executors:** ThreadPoolExecutor for CPU-bound tasks
- **Subprocess:** Async subprocess for FFmpeg/yt-dlp
- **WebSocket:** Bidirectional real-time communication
- **State Management:** WebSocketState checks

---

## ğŸš€ Performance Optimizations

### Recent Improvements (2025-10-31)
1. âœ… Removed 146 lines of dead code
2. âœ… Fixed 5 blocking I/O operations
3. âœ… Added thread-safe model loading
4. âœ… Moved diarization to executor
5. âœ… Cached index.html at startup
6. âœ… Added WebSocket state checks
7. âœ… Real-time progress updates
8. âœ… 100% completion guarantee

### Performance Metrics
- **Model Loading:** < 5 seconds (cached)
- **Download:** Streaming with progress
- **Transcription:** Real-time with chunking
- **Diarization:** Parallel processing
- **Memory:** ~2GB (base) + model size
- **CPU:** Multi-threaded (configurable workers)
- **GPU:** CUDA acceleration supported

---

## ğŸ” Security

### Input Validation
- âœ… URL format validation
- âœ… File path sanitization
- âœ… Command injection prevention
- âœ… WebSocket state verification

### Resource Limits
- âœ… Timeout protection (10s metadata, 5min download)
- âœ… File size limits
- âœ… Queue size limits
- âœ… Rate limiting (recommended, not implemented)

### Error Handling
- âœ… Graceful degradation
- âœ… Exception catching
- âœ… Detailed logging
- âœ… User-friendly error messages

---

## ğŸŒ Internationalization

### Supported Languages
- **Primary:** Hebrew (he)
- **Multilingual:** 50+ languages via Whisper models
- **UI Languages:** Hebrew (RTL) and English (LTR)

### Hebrew Optimization
- **Model:** Ivrit AI Whisper Large V3 Turbo CT2
- **Speaker Labels:** ×“×•×‘×¨_1, ×“×•×‘×¨_2, ×“×•×‘×¨_3...
- **RTL Support:** Full right-to-left UI
- **Font Rendering:** Hebrew-optimized fonts

---

## ğŸ“Š API Endpoints

### Public Endpoints
- `GET /` - Web UI (HTML)
- `GET /health` - Health check
- `GET /gpu` - GPU diagnostics
- `POST /api/video-info` - YouTube metadata
- `GET /api/cache/stats` - Cache statistics
- `POST /api/cache/clear` - Clear audio cache
- `GET /api/download-cache/stats` - Download cache stats
- `POST /api/download-cache/clear` - Clear download cache
- `WS /ws/transcribe` - WebSocket transcription

### WebSocket API
See [API.md](API.md) for detailed documentation.

---

## ğŸ³ Docker Deployment

### Two Dockerfile Variants

#### 1. **Dockerfile** (Standard)
- **Base:** Python 3.11-slim
- **Models:** openai-whisper + whisper.cpp (GGML)
- **GPU:** CUDA 11.8 support
- **Size:** ~5GB
- **Use Case:** General purpose

#### 2. **Dockerfile.ivrit** (Recommended)
- **Base:** PyTorch 2.4.1 + CUDA 12.1
- **Models:** faster-whisper (CT2) + Ivrit AI
- **Pre-cached:** Ivrit models downloaded during build
- **Size:** ~8GB
- **Use Case:** Hebrew-optimized, production

### Build & Run

```bash
# Build Ivrit-optimized image
docker build -f Dockerfile.ivrit -t transcription-ivrit .

# Run with GPU
docker run --gpus all -p 8009:8009 -e DEEPGRAM_API_KEY=xxx transcription-ivrit

# Run without GPU
docker run -p 8009:8009 -e IVRIT_DEVICE=cpu transcription-ivrit
```

---

## ğŸ§ª Testing

### Manual Testing
- âœ… YouTube URLs (various formats)
- âœ… Live streams (HLS)
- âœ… Direct video/audio files
- âœ… Diarization (2+ speakers)
- âœ… Hebrew and English content
- âœ… Model switching
- âœ… Cache hit/miss
- âœ… Error conditions

### Automated Testing
- âš ï¸ Unit tests not implemented
- âš ï¸ Integration tests not implemented
- âš ï¸ Load testing not performed

---

## ğŸ“ Environment Variables

### Required
```bash
DEEPGRAM_API_KEY=xxx               # For Deepgram transcription
```

### Optional
```bash
# Model Configuration
WHISPER_MODEL=whisper-v3-turbo     # Default model
IVRIT_MODEL_NAME=ivrit-ai/...      # Ivrit model path
IVRIT_DEVICE=cuda                  # cuda or cpu
IVRIT_COMPUTE_TYPE=float16         # Model precision
IVRIT_BEAM_SIZE=5                  # Beam search size

# Caching
AUDIO_CACHE_ENABLED=true           # Enable audio cache
CACHE_MAX_SIZE_MB=1000             # Max cache size

# Performance
PARALLEL_WORKERS=4                 # Parallel chunk workers
YTDLP_CHUNK_SECONDS=60             # Chunk size

# Server
PORT=8009                          # Server port
HOST=0.0.0.0                       # Bind address
```

---

## ğŸ“š Documentation

### Available Documents
- **PROJECT_SUMMARY.md** - This file
- **API.md** - Complete API documentation
- **APP_PY_ANALYSIS.md** - Function-level code analysis
- **FEATURE_VIDEO_METADATA.md** - Video metadata feature
- **FIXES_COMPLETED_*.md** - Bug fix documentation
- **PLAN_*.md** - Implementation plans
- **README.md** - Quick start guide
- **QUICKSTART.md** - Setup instructions
- **DEPLOYMENT.md** - Deployment guide

---

## ğŸ”® Roadmap

### Planned Features
- [ ] Unit test suite
- [ ] Rate limiting per IP
- [ ] User authentication
- [ ] Multi-user support
- [ ] Transcript export (SRT, VTT)
- [ ] Real-time translation
- [ ] Playlist support
- [ ] Audio quality selection

### Known Limitations
- No batch processing
- No speaker name customization
- No transcript editing
- No audio preprocessing options
- Single-instance only (no clustering)

---

## ğŸ“Š Statistics

### Code Metrics
- **Total Lines:** 3,618 (app.py)
- **Functions:** 48
- **Classes:** 3
- **API Endpoints:** 9
- **WebSocket Endpoints:** 1
- **Dependencies:** 25 packages

### Model Support
- **Whisper Models:** 8 variants
- **Ivrit Models:** 3 variants
- **Deepgram:** Nova-2, Nova-3
- **Diarization:** Pyannote 3.1

### Platform Support
- **OS:** Linux (Docker)
- **Python:** 3.11+
- **GPU:** NVIDIA CUDA 11.8+
- **RAM:** 4GB minimum, 8GB recommended
- **Storage:** 10GB for models + cache

---

## ğŸ¤ Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ“„ License

Proprietary - All rights reserved

---

## ğŸ™ Acknowledgments

- **OpenAI Whisper** - Speech recognition models
- **Ivrit AI** - Hebrew-optimized models
- **Deepgram** - Cloud transcription API
- **Pyannote.audio** - Speaker diarization
- **FFmpeg** - Audio processing
- **yt-dlp** - Video download

---

**Maintained by:** oznav2  
**Repository:** https://github.com/oznav2/live_transcribe  
**Status:** Active Development
