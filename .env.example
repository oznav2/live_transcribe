# Environment variables for Live Transcription app

# ==============================================================================
# DEEPGRAM CONFIGURATION (Optional - for cloud transcription)
# ==============================================================================
# Fill in your actual Deepgram API key. Do not include trailing spaces or characters.
# Get your API key from: https://console.deepgram.com/
DEEPGRAM_API_KEY=your_deepgram_api_key_here

# Deepgram settings
DEEPGRAM_TIME_LIMIT=3600          # Time limit in seconds (0 for unlimited)
DEEPGRAM_MODEL=nova-3              # Deepgram model to use
DEEPGRAM_LANGUAGE=en-US            # Default language for Deepgram
DEEPGRAM_TRANSCRIPT_ONLY=true      # Only return transcript (no metadata)

# ==============================================================================
# PRIMARY TRANSCRIPTION MODEL (faster_whisper with Ivrit CT2)
# ==============================================================================
# Main model selection - ivrit-ct2 is the default and recommended model
# Options: ivrit-ct2, ivrit-v3-turbo, whisper-v3-turbo, deepgram
WHISPER_MODEL=ivrit-ct2

# Ivrit CT2 model configuration (for Hebrew transcription)
IVRIT_MODEL_NAME=ivrit-ai/whisper-large-v3-turbo-ct2
IVRIT_DEVICE=cuda                  # Use 'cuda' for GPU or 'cpu' for CPU-only
IVRIT_COMPUTE_TYPE=float16         # Use 'float16' for GPU or 'int8' for CPU
IVRIT_BEAM_SIZE=5                  # Beam search size (higher = better quality, slower)

# ==============================================================================
# APPLICATION SETTINGS
# ==============================================================================
PORT=8009                          # Port for the web server

# Caching settings
AUDIO_CACHE_ENABLED=true           # Enable audio caching for performance

# Processing settings (optional)
USE_PARALLEL_TRANSCRIPTION=false   # Enable parallel chunk processing
PARALLEL_WORKERS=2                 # Number of parallel workers if enabled

# ==============================================================================
# GPU CONFIGURATION (Optional)
# ==============================================================================
# Uncomment and modify if you need specific GPU settings
# CUDA_VISIBLE_DEVICES=0           # Which GPU to use (0, 1, etc.)
# NVIDIA_VISIBLE_DEVICES=all       # Docker GPU visibility

# ==============================================================================
# NOTES
# ==============================================================================
# 1. NEVER use 'ivrit-large-v3-turbo' - this was the old GGML model (removed)
# 2. Use 'ivrit-ct2' for best Hebrew transcription performance
# 3. For CPU-only systems, set IVRIT_DEVICE=cpu and IVRIT_COMPUTE_TYPE=int8
# 4. Deepgram API is optional - leave blank if not using cloud transcription